{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1n5wJN4_PWV",
        "outputId": "6741207a-8757-4d4d-83fa-cf28b7054fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error before removing least important features: 179476.4312564365\n",
            "\n",
            "Feature ranking:\n",
            "1. Feature Distance (0.27642548087435304)\n",
            "2. Feature Rooms (0.21859591163938233)\n",
            "3. Feature Postcode (0.1891360409212323)\n",
            "4. Feature Landsize (0.07666168167616283)\n",
            "5. Feature BuildingArea (0.05089059548042887)\n",
            "6. Feature Longtitude (0.043968289315635255)\n",
            "7. Feature Lattitude (0.04358082967759252)\n",
            "8. Feature Propertycount (0.03468505475918846)\n",
            "9. Feature YearBuilt (0.025026372736625536)\n",
            "10. Feature Bathroom (0.01958544012834771)\n",
            "11. Feature Car (0.016252519882662745)\n",
            "12. Feature Bedroom2 (0.005191782908388576)\n",
            "\n",
            "Least important features removed: Index(['Bedroom2', 'Bathroom', 'Car'], dtype='object')\n",
            "Mean Absolute Error after removing least important features: 183336.16241149075\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/melbourne_housing_raw.csv'\n",
        "melbourne_data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop rows with missing target (Price) values\n",
        "melbourne_data_clean = melbourne_data.dropna(subset=['Price'])\n",
        "\n",
        "# Split features and target\n",
        "X = melbourne_data_clean.drop(columns=['Price'])\n",
        "y = melbourne_data_clean['Price']\n",
        "\n",
        "# Drop object-type columns (categorical) for this numerical analysis\n",
        "X_numerical = X.select_dtypes(include=['float64', 'int64'])\n",
        "\n",
        "# Handle missing values with mean imputation\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_numerical_imputed = pd.DataFrame(imputer.fit_transform(X_numerical), columns=X_numerical.columns)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numerical_imputed, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the random forest model\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model\n",
        "y_pred = rf.predict(X_test)\n",
        "mae_before = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error before removing least important features:\", mae_before)\n",
        "\n",
        "# Get feature importances\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"\\nFeature ranking:\")\n",
        "for f in range(X_numerical_imputed.shape[1]):\n",
        "    print(f\"{f + 1}. Feature {X_numerical_imputed.columns[indices[f]]} ({importances[indices[f]]})\")\n",
        "\n",
        "# Remove the least important features (let's say bottom 20% least important features)\n",
        "threshold = np.percentile(importances, 20)\n",
        "least_important_features = X_numerical_imputed.columns[importances < threshold]\n",
        "X_train_reduced = X_train.drop(columns=least_important_features)\n",
        "X_test_reduced = X_test.drop(columns=least_important_features)\n",
        "\n",
        "# Train the model again after removing the least important features\n",
        "rf_reduced = RandomForestRegressor(random_state=42)\n",
        "rf_reduced.fit(X_train_reduced, y_train)\n",
        "\n",
        "# Make predictions and evaluate the reduced model\n",
        "y_pred_reduced = rf_reduced.predict(X_test_reduced)\n",
        "mae_after = mean_absolute_error(y_test, y_pred_reduced)\n",
        "\n",
        "print(\"\\nLeast important features removed:\", least_important_features)\n",
        "print(\"Mean Absolute Error after removing least important features:\", mae_after)\n"
      ]
    }
  ]
}